{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469dbc47-4ea2-417f-a4bd-3fa2c5c0b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a17d52-98d2-4407-adbd-07662d817d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.active_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36de7698-9ab5-45a4-80dc-912b9d7f11a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MainThread(MainThread, started 137017489358848)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.current_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42eaf3b6-001e-4211-a722-71ad9ec20463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_MainThread(MainThread, started 137017489358848)>,\n",
       " <Thread(IOPub, started daemon 137017420793408)>,\n",
       " <Heartbeat(Heartbeat, started daemon 137017412400704)>,\n",
       " <Thread(Thread-2 (_watch_pipe_fd), started daemon 137017387222592)>,\n",
       " <Thread(Thread-3 (_watch_pipe_fd), started daemon 137017040041536)>,\n",
       " <ControlThread(Control, started daemon 137017031648832)>,\n",
       " <HistorySavingThread(IPythonHistorySavingThread, started 137017021158976)>,\n",
       " <ParentPollerUnix(Thread-1, started daemon 137017012766272)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f22b400-c899-4a54-b55e-3ad3ef28aa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.TIMEOUT_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8cc62-a963-4ac4-98af-dbaf77af0d23",
   "metadata": {},
   "source": [
    "## Threading use case\n",
    "\n",
    "`Major impact` - Tasks that spend much of their time waiting for external events (I/O) are generally good candidates for threading\n",
    "\n",
    "`Minor impact` - Tasks that require heavy CPU computation & spend little time waiting for external events (these might not run faster)\n",
    "\n",
    "If the usecase is to perform a CPU-Bound operation then `multiprocessing` module is to be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ae1d4-6dff-4be5-841e-d9dc37a034bb",
   "metadata": {},
   "source": [
    "### Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00391133-63d6-47f3-ae74-3eecf61deacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:35:46: Main    : before creating thread\n",
      "19:35:46: Main    : before running thread\n",
      "19:35:46: Thread 1: starting\n",
      "19:35:46: Main    : wait for the thread to finish\n",
      "19:35:46: Main    : all done\n",
      "19:35:48: Thread 1: finishing\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def thread_function(name):\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    time.sleep(2)\n",
    "    logging.info(\"Thread %s: finishing\", name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    logging.info(\"Main    : before creating thread\")\n",
    "    \n",
    "    x = threading.Thread(target=thread_function, args=(1,))\n",
    "    \n",
    "    # # Creating a Daemon thread\n",
    "    # x = threading.Thread(target=thread_function, args=(1,), daemon=True)\n",
    "    \n",
    "    logging.info(\"Main    : before running thread\")\n",
    "    x.start()\n",
    "    logging.info(\"Main    : wait for the thread to finish\")\n",
    "    # x.join() # comment/uncomment this to check the difference\n",
    "    logging.info(\"Main    : all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d9a38-ac09-470a-9c75-a3e7a5122fb0",
   "metadata": {},
   "source": [
    "**Daemon**\n",
    "\n",
    "In CS, it refers to a process that runs in background. In case of threading its a bit more specific.\n",
    "\n",
    "It refers to a thread which runs in the background without worrying to shutdown because it terminates as the program exits.\n",
    "\n",
    "**Non Daemon**\n",
    "\n",
    "The program which starts these threads wait for the threads to complete before it terminates\n",
    "\n",
    "*NOTE*\n",
    "\n",
    "In the above example (x.join() when its commented), you will notice a small pause after the `all done` print. This is because the program is waiting for the `non daemon` thread to complete.\n",
    "\n",
    "Internally, the threading._shutdown() goes through all the alive threads and calls .join() on those threads which don't have `daemon` flag set. This is what we also can manually add (as seen in the above code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016a968-8bc6-4d8b-8495-d62e00320a2f",
   "metadata": {},
   "source": [
    "### Multiple Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9d9160-ed31-438a-b180-2e07dcc55b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:44:19: Main    : create and start thread 0.\n",
      "16:44:19: Thread 0: starting\n",
      "16:44:19: Main    : create and start thread 1.\n",
      "16:44:19: Thread 1: starting\n",
      "16:44:19: Main    : create and start thread 2.\n",
      "16:44:19: Thread 2: starting\n",
      "16:44:19: Main    : before joining thread 0.\n",
      "16:44:21: Thread 0: finishing\n",
      "16:44:21: Thread 1: finishing\n",
      "16:44:21: Main    : thread 0 done\n",
      "16:44:21: Main    : before joining thread 1.\n",
      "16:44:21: Thread 2: finishing\n",
      "16:44:21: Main    : thread 1 done\n",
      "16:44:21: Main    : before joining thread 2.\n",
      "16:44:21: Main    : thread 2 done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    The order in which threads are run is decided by the OS & its hard to predict it. Therefore, running the \n",
    "    below code multiple times will results in different finishing print order.\n",
    "\n",
    "    Fortunately, Python provide several primitives that can help to coordinate threads (later section)\n",
    "\"\"\"\n",
    "\n",
    "threads = list()\n",
    "for index in range(3):\n",
    "    logging.info(\"Main    : create and start thread %d.\", index)\n",
    "    x = threading.Thread(target=thread_function, args=(index,))\n",
    "    threads.append(x)\n",
    "    x.start()\n",
    "\n",
    "for index, thread in enumerate(threads):\n",
    "    logging.info(\"Main    : before joining thread %d.\", index)\n",
    "    thread.join()\n",
    "    logging.info(\"Main    : thread %d done\", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930139ac-9b6c-4fb2-9317-ec95dc88d10d",
   "metadata": {},
   "source": [
    "### ThreadPoolExecutor\n",
    "\n",
    "An easier way to start up a grp of threads.\n",
    "\n",
    "The easiest way is to create using the `with` context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e41d8acf-913b-43c2-bc69-17b56b42605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:40:05: Thread 0: starting\n",
      "16:40:05: Thread 1: starting\n",
      "16:40:05: Thread 2: starting\n",
      "16:40:07: Thread 0: finishing\n",
      "16:40:07: Thread 1: finishing\n",
      "16:40:07: Thread 2: finishing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    The `ThreadPoolExecutor` at the end of the `with` statement calls the .join() on each of the \\n    thread in the Pool.\\n\\n    Its highly recommended to use `ThreadPoolExecutor` with `with context manager` as there will be no case\\n    of issue caused due to forgetting to implement the `.join()` call\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# [rest of code]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        executor.map(thread_function, range(3))\n",
    "\n",
    "\"\"\"\n",
    "    The `ThreadPoolExecutor` at the end of the `with` statement calls the .join() on each of the \n",
    "    thread in the Pool.\n",
    "\n",
    "    Its highly recommended to use `ThreadPoolExecutor` with `with context manager` as there will be no case\n",
    "    of issue caused due to forgetting to implement the `.join()` call\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052e299-f626-4b46-997c-14aaf44cbed4",
   "metadata": {},
   "source": [
    "**Note**: Using a ThreadPoolExecutor can cause some confusing errors.\n",
    "\n",
    "For example, if you call a function that takes no parameters, but you pass it parameters in .map(), the thread will throw an exception.\n",
    "\n",
    "Unfortunately, ThreadPoolExecutor will hide that exception, and (in the case above) the program terminates with no output. This can be quite confusing to debug at first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d41787-de83-4194-9a1c-78bca18ad91d",
   "metadata": {},
   "source": [
    "### Race Conditions\n",
    "\n",
    "- Race conditions can occur when two or more threads access a shared piece of data or resource.\n",
    "- Frequently, they only occur rarely, and they can produce confusing results. As you can imagine, this makes them quite difficult to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45f22a7-8220-41c0-bf77-24b52c0c833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a race condition\n",
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "\n",
    "    def update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        local_copy = self.value\n",
    "        local_copy += 1\n",
    "        time.sleep(0.1)\n",
    "        self.value = local_copy\n",
    "        logging.info(\"Thread %s: finishing update\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fb30090-e446-463c-b581-d194a7123b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:49:18: Testing update. Starting value is 0.\n",
      "16:49:18: Thread 0: starting update\n",
      "16:49:18: Thread 1: starting update\n",
      "16:49:18: Thread 0: finishing update\n",
      "16:49:18: Thread 1: finishing update\n",
      "16:49:18: Testing update. Ending value is 1.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    database = FakeDatabase()\n",
    "    logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for index in range(2):\n",
    "            executor.submit(database.update, index)\n",
    "    logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e162da-7cb4-47fb-b24b-87becece26b8",
   "metadata": {},
   "source": [
    "Above the expected value should be 2 (as python threads run one at a time)\n",
    "\n",
    "When a thread starts it creates a `local_copy`. Therefore, thread 1 creates copy -> update -> sleep\n",
    "\n",
    "When thread 1 sleeps thread 2 gets the opportunity to start -> copy -> update. Notice that the `value` has not been updated. So, thread 2 also copies 0.\n",
    "\n",
    "Then each thread update the `self.value` to be 1 as they aren't aware of other threads doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74496f-d51e-408e-98d4-ee97b998477b",
   "metadata": {},
   "source": [
    "### Basic Sync Using `Lock`\n",
    "\n",
    "One of the ways to avoid `race conditions`\n",
    "\n",
    "A Lock is an object that acts like a hall pass. Only one thread at a time can have the Lock. Any other thread that wants the Lock must wait until the owner of the Lock gives it up.\n",
    "\n",
    "In some other languages this same idea is called a `mutex`.\n",
    "\n",
    "`.acquire()` and `.release()` are the two basic functions used to perform this.\n",
    "\n",
    "**NOTE** - If the thread doesn't ever release the lock then in that case the program will be stuck.\n",
    "\n",
    "Fortunately, Python’s Lock will also operate as a `context manager`, so you can use it in a with statement, and it gets released automatically when the with block exits for any reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9591536a-cb23-4069-b852-4117cbfd2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def locked_update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        logging.debug(\"Thread %s about to lock\", name)\n",
    "\n",
    "        # Using as a context manager\n",
    "        with self._lock: # using the .acquire() internally\n",
    "            logging.debug(\"Thread %s has lock\", name)\n",
    "            local_copy = self.value\n",
    "            local_copy += 1\n",
    "            time.sleep(0.1)\n",
    "            self.value = local_copy\n",
    "            logging.debug(\"Thread %s about to release lock\", name)\n",
    "            \n",
    "        # released using the .release() internally\n",
    "        logging.debug(\"Thread %s after release\", name)\n",
    "        logging.info(\"Thread %s: finishing update\", name)\n",
    "\n",
    "# ASSUMPTION :: here we are using sleep but because it has locked the resource another thread using the\n",
    "# same resource is not started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b672703a-5e74-45b0-a969-3e7fc33bcc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:40:29: Testing update. Starting value is 0.\n",
      "19:40:29: Thread 0: starting update\n",
      "19:40:29: Thread 1: starting update\n",
      "19:40:29: Thread 0: finishing update\n",
      "19:40:29: Thread 1: finishing update\n",
      "19:40:29: Testing update. Ending value is 2.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    database = FakeDatabase()\n",
    "    logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for index in range(2):\n",
    "            executor.submit(database.locked_update, index)\n",
    "    logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85f59a-8dce-4e2f-90e6-d6802a1341d7",
   "metadata": {},
   "source": [
    "```python\n",
    "import threading\n",
    "\n",
    "l = threading.Lock()\n",
    "print(\"before first acquire\")\n",
    "l.acquire()\n",
    "print(\"before second acquire\")\n",
    "l.acquire()\n",
    "print(\"acquired lock twice\")\n",
    "```\n",
    "\n",
    "The above will hang as the lock is not released ( `Deadlock` )\n",
    "\n",
    "Here there is no thread creation so what is getting the lock. As far as my understanding goes, the program irrespective of therad creation runs on `main thread` so the main thread has the lock & it again calls for the lock before releasing resulting in a deadlock.\n",
    "\n",
    "Deadlocks usually happen from one of two subtle things:\n",
    "- An implementation bug where a Lock is not released properly\n",
    "- A design issue where a utility function needs to be called by functions that might or might not already have the Lock\n",
    "\n",
    "The 1st issue can be greatly reduced using `context manager form`\n",
    "\n",
    "The 2nd issue can be tackled using `RLock`. It allows a thread to .acquire() an RLock multiple times before it calls .release(). That thread is still required to call .release() the same number of times it called .acquire(), but it should be doing that anyway.\n",
    "\n",
    "`Lock` & `RLock` are the two basic tools used in threaded programming to prevent race conditions\n",
    "\n",
    "I/O & Memory bound operations in a program release the GIL for other threads to keep the CPU busy\n",
    "- open() and close() file operations\n",
    "- read(), write(), readline(), readlines(), and writelines()\n",
    "- socket.recv(), socket.send(), socket.recvfrom(), socket.sendto()\n",
    "- Database operations using libraries like sqlite3, psycopg2, MySQLdb, etc.\n",
    "- Certain operations in the `collections` module like deque, Queue, Counter, etc.\n",
    "- Some operations in the os module, such as os.system(), os.fork(), etc.\n",
    "- subprocess module functions like subprocess.run(), subprocess.Popen()\n",
    "- Async I/O operations (asyncio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870974f-0433-43eb-b994-d3049432a9fd",
   "metadata": {},
   "source": [
    "### Producer Consumer Threading\n",
    "\n",
    "This is a standard computer science problem used to look at threading or process synchronization issues,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94c638-e2f5-403f-8b67-bee2a8b5d406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68fe346a-86e4-41a9-94a8-aa71b6e7efe4",
   "metadata": {},
   "source": [
    "#### Product Consumer using Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b0916a-92e7-4865-9b70-dd0492868d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import logging\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928bb37d-4141-4d97-93e6-bebdbdc446cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    Class to allow a single element pipeline between producer and consumer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.message = 0\n",
    "        self.producer_lock = threading.Lock()\n",
    "        self.consumer_lock = threading.Lock()\n",
    "        self.consumer_lock.acquire()\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to acquire getlock\", name)\n",
    "        self.consumer_lock.acquire()\n",
    "        logging.debug(\"%s:have getlock\", name)\n",
    "        message = self.message\n",
    "        logging.debug(\"%s:about to release setlock\", name)\n",
    "        self.producer_lock.release()\n",
    "        logging.debug(\"%s:setlock released\", name)\n",
    "        return message\n",
    "\n",
    "    def set_message(self, message, name):\n",
    "        logging.debug(\"%s:about to acquire setlock\", name)\n",
    "        self.producer_lock.acquire()\n",
    "        logging.debug(\"%s:have setlock\", name)\n",
    "        self.message = message\n",
    "        logging.debug(\"%s:about to release getlock\", name)\n",
    "        self.consumer_lock.release()\n",
    "        logging.debug(\"%s:getlock released\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b873380-0340-4bfa-ae59-9417f5b7ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SENTINEL = object()\n",
    "\n",
    "def producer(pipeline):\n",
    "    \"\"\"Pretend we're getting a message from the network.\"\"\"\n",
    "    for index in range(10):\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    # Send a sentinel message to tell consumer we're done\n",
    "    pipeline.set_message(SENTINEL, \"Producer\")\n",
    "\n",
    "def consumer(pipeline):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    message = 0\n",
    "    while message is not SENTINEL:\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        if message is not SENTINEL:\n",
    "            logging.info(\"Consumer storing message: %s\", message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2777a356-c223-4f1d-a974-73408017de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:37:20: Producer got message: 27\n",
      "07:37:20: Producer got message: 83\n",
      "07:37:20: Consumer storing message: 27\n",
      "07:37:20: Producer got message: 100\n",
      "07:37:20: Consumer storing message: 83\n",
      "07:37:20: Producer got message: 47\n",
      "07:37:20: Consumer storing message: 100\n",
      "07:37:20: Producer got message: 82\n",
      "07:37:20: Consumer storing message: 47\n",
      "07:37:20: Producer got message: 63\n",
      "07:37:20: Consumer storing message: 82\n",
      "07:37:20: Producer got message: 33\n",
      "07:37:20: Consumer storing message: 63\n",
      "07:37:20: Producer got message: 72\n",
      "07:37:20: Consumer storing message: 33\n",
      "07:37:20: Producer got message: 97\n",
      "07:37:20: Consumer storing message: 72\n",
      "07:37:20: Producer got message: 90\n",
      "07:37:20: Consumer storing message: 97\n",
      "07:37:20: Consumer storing message: 90\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "    # logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(producer, pipeline)\n",
    "        executor.submit(consumer, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43b0fd-be88-40e6-b837-0e1c2826fe2e",
   "metadata": {},
   "source": [
    "#### Producer Consumer using Queue\n",
    "\n",
    "Here there is no need to include all the locking because `Queue` has the locking mechanism incorporated internally. `Queue` is `thread-safe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca914e9-eb2b-448c-9f61-56aaf7cb1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "class Pipeline(queue.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__(maxsize=10)\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to get from queue\", name)\n",
    "        value = self.get()\n",
    "        logging.debug(\"%s:got %d from queue\", name, value)\n",
    "        return value\n",
    "\n",
    "    def set_message(self, value, name):\n",
    "        logging.debug(\"%s:about to add %d to queue\", name, value)\n",
    "        self.put(value)\n",
    "        logging.debug(\"%s:added %d to queue\", name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4090fc-438c-4357-9be3-cd66f47f5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def producer(pipeline, event):\n",
    "    \"\"\"Pretend we're getting a number from the network.\"\"\"\n",
    "    while not event.is_set():\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    logging.info(\"Producer received EXIT event. Exiting\")\n",
    "\n",
    "def consumer(pipeline, event):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    while not event.is_set() or not pipeline.empty():\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        logging.info(\n",
    "            \"Consumer storing message: %s  (queue size=%s)\",\n",
    "            message,\n",
    "            pipeline.qsize(),\n",
    "        )\n",
    "\n",
    "    logging.info(\"Consumer received EXIT event. Exiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f32343-285e-4715-bc88-9a4ddf0b6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "    # logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    event = threading.Event()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(producer, pipeline, event)\n",
    "        executor.submit(consumer, pipeline, event)\n",
    "\n",
    "        time.sleep(0.01)\n",
    "        logging.info(\"Main: about to set event\")\n",
    "        event.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83a977-8b20-4326-97a4-547a367df645",
   "metadata": {},
   "source": [
    "### Threading Objects\n",
    "\n",
    "There are a few more primitives offered by the Python threading module\n",
    "\n",
    "#### Semaphore\n",
    "\n",
    "A Semaphore is a counter with a few special properties.\n",
    "- The first one is that the counting is atomic.\n",
    "- This means that there is a guarantee that the operating system will not swap out the thread in the middle of incrementing or decrementing the counter.\n",
    "- The internal counter is incremented when you call .release() and decremented when you call .acquire().\n",
    "- The next special property is that if a thread calls .acquire() when the counter is zero, that thread will block until a different thread calls .release() and increments the counter to one.\n",
    "\n",
    "These are usually used to protect resources\n",
    "\n",
    "#### Timer\n",
    "\n",
    "A threading.Timer is a way to schedule a function to be called after a certain amount of time has passed\n",
    "\n",
    "```python\n",
    "t = threading.Timer(30.0, my_function)\n",
    "t.start()\n",
    "```\n",
    "The function will be called on a new thread at some point after the specified time, but be aware that there is `no promise that it will be called exactly at the time you want`.\n",
    "\n",
    "The function call can be cancel in any required case by using `.cancel()`\n",
    "\n",
    "#### Barrier\n",
    "\n",
    "- A threading.Barrier can be used to keep a fixed number of threads in sync.\n",
    "- When creating a Barrier, the caller must specify how many threads will be synchronizing on it\n",
    "- Each thread calls .wait() on the Barrier. They all will remain blocked until the specified number of threads are waiting, and then the are all released at the same time.\n",
    "\n",
    "Remember that threads are scheduled by the operating system so, even though all of the threads are released simultaneously, they will be scheduled to run one at a time.\n",
    "\n",
    "One use for a Barrier is to allow a pool of threads to initialize themselves. Having the threads wait on a Barrier after they are initialized will ensure that none of the threads start running before all of the threads are finished with their initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003420c5-dfd2-4947-8a94-0e83878bb1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
