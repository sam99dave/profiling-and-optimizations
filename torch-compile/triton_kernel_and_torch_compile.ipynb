{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fjOpy-kjuQbG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils._triton import has_triton"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector ADD Triton Kernel"
      ],
      "metadata": {
        "id": "rQiGnClO5qoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not has_triton():\n",
        "  print(f'Skipping because triton is not present')\n",
        "else:\n",
        "  import triton\n",
        "  import triton.language as tl\n",
        "\n",
        "  @triton.jit\n",
        "  def add_kernel(\n",
        "      x_ptr,\n",
        "      y_ptr,\n",
        "      output_ptr,\n",
        "      n_elements,\n",
        "      BLOCK_SIZE: tl.constexpr\n",
        "  ):\n",
        "    row_start = tl.program_id(0)\n",
        "    offsets = row_start * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "\n",
        "    mask = offsets < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "    y = tl.load(y_ptr + offsets, mask=mask)\n",
        "\n",
        "    output = x + y\n",
        "\n",
        "    tl.store(output_ptr + offsets, output, mask=mask)\n",
        "\n",
        "\n",
        "  def add_fn(x: torch.Tensor, y: torch.Tensor):\n",
        "    z = torch.empty_like(x)\n",
        "\n",
        "    n_elements = x.numel()\n",
        "\n",
        "    grid = lambda meta: ((n_elements + 1 // meta['BLOCK_SIZE']), )\n",
        "\n",
        "    add_kernel[grid](x, y, z, n_elements, BLOCK_SIZE = 4)\n",
        "\n",
        "    return z\n",
        "\n",
        "  x = torch.randn(4, device='cuda')\n",
        "  y = torch.randn(4, device ='cuda')\n",
        "\n",
        "  out = add_fn(x, y)\n",
        "  print(f\"Vector addition of\\nX:\\t{x}\\nY:\\t{y}\\nis equal to\\n{out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwd2Lvcjyc_2",
        "outputId": "6f0fec39-d495-453f-ad99-a6974793bf00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition of\n",
            "X:\ttensor([-0.1338, -0.9214,  0.2518,  0.0580], device='cuda:0')\n",
            "Y:\ttensor([-1.6395,  0.7362,  0.2845, -1.1175], device='cuda:0')\n",
            "is equal to\n",
            "tensor([-1.7733, -0.1852,  0.5362, -1.0595], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trtiton Autotune + Compile\n",
        "\n",
        "**NOTE**\n",
        "\n",
        "torch.compile only supports configs and key arguments to triton.autotune.\n",
        "\n",
        "As of June 2024\n",
        "\n",
        "LIMITATIONS:\n",
        "\n",
        "- Tensor Subclasses: Currently, there is no support for tensor subclasses and other advanced features.\n",
        "\n",
        "- Triton Features: While `triton.heuristics` can be used either standalone or before `triton.autotune`, it cannot be used after `triton.autotune`. This implies that if triton.heuristics and triton.autotune are to be used together, `triton.heuristics` must be used first."
      ],
      "metadata": {
        "id": "QPnPkT2x5tIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not has_triton():\n",
        "  print(f'Skipping because triton is not present')\n",
        "else:\n",
        "  import triton\n",
        "  import triton.language as tl\n",
        "\n",
        "  @triton.autotune(\n",
        "      configs=[\n",
        "          triton.Config({\"BLOCK_SIZE\": 4}, num_stages=3, num_warps=8),\n",
        "          triton.Config({\"BLOCK_SIZE\": 4}, num_stages=4, num_warps=4),\n",
        "          triton.Config({\"BLOCK_SIZE\": 2}, num_stages=3, num_warps=8),\n",
        "          triton.Config({\"BLOCK_SIZE\": 2}, num_stages=4, num_warps=4),\n",
        "      ],\n",
        "      key = [],\n",
        "  )\n",
        "  @triton.jit\n",
        "  def add_kernel_autotuned(\n",
        "      x_ptr,\n",
        "      y_ptr,\n",
        "      output_ptr,\n",
        "      n_elements,\n",
        "      BLOCK_SIZE: tl.constexpr\n",
        "  ):\n",
        "    row_start = tl.program_id(0)\n",
        "    offsets = row_start * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "\n",
        "    mask = offsets < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "    y = tl.load(y_ptr + offsets, mask=mask)\n",
        "\n",
        "    output = x + y\n",
        "\n",
        "    tl.store(output_ptr + offsets, output, mask=mask)\n",
        "\n",
        "  @torch.compile(fullgraph=True)\n",
        "  def add_fn_autotuned(x: torch.Tensor, y: torch.Tensor):\n",
        "    z = torch.empty_like(x)\n",
        "\n",
        "    n_elements = x.numel()\n",
        "\n",
        "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
        "\n",
        "    add_kernel_autotuned[grid](x, y, z, n_elements)\n",
        "\n",
        "    return z\n",
        "\n",
        "  x = torch.randn(4, device='cuda')\n",
        "  y = torch.randn(4, device ='cuda')\n",
        "\n",
        "  out = add_fn_autotuned(x, y)\n",
        "  print(f\"Vector addition of\\nX:\\t{x}\\nY:\\t{y}\\nis equal to\\n{out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0-DL4os0T90",
        "outputId": "0388ee28-8179-4c49-de5f-9fed148eec85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition of\n",
            "X:\ttensor([-0.4056, -2.5999, -0.6385,  0.2939], device='cuda:0')\n",
            "Y:\ttensor([-0.0749, -0.0383,  1.1321, -0.0747], device='cuda:0')\n",
            "is equal to\n",
            "tensor([-0.4805, -2.6382,  0.4936,  0.2192], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# naive add\n",
        "def add(x, y):\n",
        "  return x + y\n",
        "\n",
        "# compiled\n",
        "@torch.compile(fullgraph=True, mode='reduce-overhead')\n",
        "def add_compiled(x, y):\n",
        "  return x + y"
      ],
      "metadata": {
        "id": "ndXeNI6C7u80"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit - 10\n",
        "add_fn_autotuned(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DNkTMcx6bTu",
        "outputId": "639b8dbc-5871-4a76-e082-dc6f6bee93f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3 ns ± 0.0772 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.9640,  2.1937, -0.8272,  0.3639], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit - 10\n",
        "add_fn(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYwXxuc7qwE",
        "outputId": "d7c3aa68-d98a-4bbf-80ee-a549d1d96f8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.4 ns ± 3.43 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.9640,  2.1937, -0.8272,  0.3639], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit - 10\n",
        "add(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfl-Hy1386rt",
        "outputId": "e013d407-9230-47e0-d716-74e9260d1280"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.7 ns ± 3.18 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4805, -2.6382,  0.4936,  0.2192], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit - 10\n",
        "add_compiled(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdY29Qhs89D9",
        "outputId": "d9fdaee3-3346-4bc3-eec4-1620d98ba1a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.6 ns ± 1.13 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4805, -2.6382,  0.4936,  0.2192], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timed(fn, x, y):\n",
        "  start = torch.cuda.Event(enable_timing=True)\n",
        "  end = torch.cuda.Event(enable_timing=True)\n",
        "  start.record()\n",
        "  _ = fn(x, y)\n",
        "  end.record()\n",
        "\n",
        "  return start.elapsed_time(end)"
      ],
      "metadata": {
        "id": "dCtziGGL9DBa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(timed(add, x, y))\n",
        "print(timed(add_compiled, x, y))\n",
        "print(timed(add_fn, x, y))\n",
        "print(timed(add_fn_autotuned, x, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqcA8lQ3923f",
        "outputId": "25f99940-4ffa-4e0d-8867-cb34a183d31a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9092479944229126\n",
            "0.5697600245475769\n",
            "0.34828799962997437\n",
            "0.42905598878860474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7H9vb7z-OPD"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}