{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb2c1f8-8056-4365-8d89-ced61a6f9c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Its useless to run on T4, checked in Colab\n",
    "# Eager implementation is faster compared to the compiled one\n",
    "# New GPUs are recommended to see the performance gain\n",
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65218b-2ed8-4773-b35b-b88d2482ce0e",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab677182-6660-4683-8177-8fc65b0cbb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.6401e-01,  1.7016e-02,  7.4052e-01, -9.0659e-01,  6.4671e-01,\n",
      "          8.7245e-02,  1.7977e+00,  5.5112e-01,  1.9435e+00,  9.7201e-01],\n",
      "        [ 5.7107e-04,  1.4846e+00,  9.9307e-01,  7.6449e-01,  1.3303e+00,\n",
      "          3.4297e-01, -5.4293e-03,  3.3660e-01,  1.5422e+00,  1.4008e-01],\n",
      "        [ 1.0293e+00,  1.8458e+00, -9.8598e-01,  1.6686e+00,  8.3647e-01,\n",
      "          8.2349e-01,  1.8490e+00,  4.4677e-01,  1.6510e+00, -1.9842e-01],\n",
      "        [ 1.9871e+00, -1.4957e-01, -3.2866e-01, -8.3208e-01, -2.7273e-01,\n",
      "          1.2441e+00, -3.4223e-02,  1.9290e+00,  1.6003e-01, -3.2757e-01],\n",
      "        [ 1.0509e+00,  5.7475e-01,  4.4471e-01,  7.0422e-01,  9.8131e-01,\n",
      "         -5.3313e-01,  1.2125e+00, -8.6652e-02,  1.0668e+00,  1.2120e+00],\n",
      "        [ 1.7042e+00,  9.5717e-01,  8.7913e-01, -1.2441e-03,  3.2436e-01,\n",
      "          1.1627e+00,  1.4027e+00,  6.2523e-02, -9.0566e-01, -1.5851e-02],\n",
      "        [ 1.4409e+00, -8.5981e-01,  3.3119e-02,  8.8452e-01, -1.3035e-03,\n",
      "          1.4828e+00,  9.7782e-01,  7.7680e-01,  1.5926e+00,  6.4390e-01],\n",
      "        [ 5.8908e-01,  8.0311e-01,  1.9160e+00, -1.1911e+00,  1.7095e-01,\n",
      "          1.1631e+00, -3.1125e-01,  8.8773e-01, -2.7540e-02,  8.5100e-01],\n",
      "        [ 6.8857e-01,  4.1617e-01,  1.3430e+00,  8.6482e-01,  1.0395e+00,\n",
      "          1.7649e-02,  1.1143e+00,  1.0566e-01, -3.8394e-02,  1.4208e+00],\n",
      "        [ 1.7986e+00,  1.1897e+00, -4.3864e-03,  1.8368e+00,  6.2401e-01,\n",
      "          9.8684e-01,  1.4504e+00,  1.0441e+00, -1.0592e-02,  3.4475e-01]])\n"
     ]
    }
   ],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "\n",
    "    return a + b\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bdfac8b-a77a-4984-bab0-d6e34e7033ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37 ns ± 0.247 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3000, -0.0321, -1.5041, -0.0557,  0.7139,  0.4382,  1.2324,  0.0062,\n",
       "         -0.0742, -0.5448],\n",
       "        [-0.0253,  0.5874, -0.4172,  0.9959,  0.7264, -0.2549,  0.5916,  0.3568,\n",
       "         -0.0798,  0.5314],\n",
       "        [ 1.6214,  1.0751, -0.0082,  0.3447, -0.3065,  0.2184,  0.5108,  1.1271,\n",
       "          0.8007,  0.5756],\n",
       "        [ 1.7139, -0.2640, -0.3761, -0.2455,  0.6209,  0.2857, -0.1122,  1.7876,\n",
       "         -0.3087,  0.6260],\n",
       "        [ 1.0469,  1.1744,  0.0434,  0.0370, -0.1157,  1.8040, -0.1989,  1.0322,\n",
       "          0.0846, -1.6194],\n",
       "        [ 0.8123,  1.9302,  1.1469,  1.0269,  0.5622, -0.4389,  0.4803,  1.2363,\n",
       "          1.9761,  1.5659],\n",
       "        [-0.8656,  0.9414,  1.5235,  1.1013,  0.3155,  0.6850,  0.7362,  1.5552,\n",
       "          0.2015, -0.3910],\n",
       "        [ 1.9176,  0.8103, -0.4016,  1.6392,  0.9168, -0.2683, -0.4712,  1.1291,\n",
       "          0.3128, -0.6004],\n",
       "        [ 1.1191,  1.7887,  0.8115,  0.0942, -0.1750,  0.1145,  0.0865, -0.5304,\n",
       "          1.5942,  1.2025],\n",
       "        [-1.9728, -0.1104,  0.4038, -0.6170,  0.3411,  0.7554,  0.0744,  0.3139,\n",
       "          1.3875,  0.0099]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit - 100\n",
    "opt_foo1(torch.randn(10, 10, device = 'cuda'), torch.randn(10, 10, device = 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ceaa05-58f3-4d0b-b354-8fbc2dbe8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.69 ns ± 0.133 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0162, -0.7898,  1.6381,  1.5643, -0.1108, -0.2654,  0.5863,  0.9334,\n",
       "          1.1033, -0.6706],\n",
       "        [ 0.3943,  1.0844,  0.3496,  1.6927,  0.2109,  1.1553,  1.3847,  0.6356,\n",
       "         -0.0574,  1.1627],\n",
       "        [ 0.2621,  0.5943,  0.4157,  0.4317,  1.8410, -0.4729,  1.5114, -0.2023,\n",
       "          0.9812,  0.3078],\n",
       "        [ 0.8464,  1.6212,  1.4751, -0.0798,  1.9011,  0.3662, -0.1116,  1.6241,\n",
       "          0.0856,  0.1323],\n",
       "        [-0.3066,  1.7269,  0.8605,  0.0395,  0.6983,  0.9367,  0.2309,  1.2733,\n",
       "         -0.6284,  0.7423],\n",
       "        [ 0.4229, -0.3339,  0.0346,  1.8498,  0.1150,  0.4196,  1.6279,  0.9852,\n",
       "          1.4195,  1.0310],\n",
       "        [ 1.5170,  1.6057,  0.2031,  0.8446, -0.4777, -0.0897,  1.9195, -0.1396,\n",
       "          0.4616,  1.4747],\n",
       "        [-0.6079,  0.1111,  1.2372,  1.1059, -0.3938,  1.9976,  0.3073,  0.6892,\n",
       "          1.3043,  1.6004],\n",
       "        [ 1.6447, -0.6716,  0.1831,  0.9261,  1.4356,  0.7705,  1.4079,  1.6754,\n",
       "         -0.6574, -1.1659],\n",
       "        [-0.6373,  0.9134,  0.6182,  0.0855,  0.4545,  0.4775,  0.9254,  0.9813,\n",
       "          1.8520, -0.2235]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit - 100\n",
    "foo(torch.randn(10, 10, device = 'cuda'), torch.randn(10, 10, device = 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e43a21-6c32-4b97-a4ad-3acc455e1530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9854,  1.0840, -0.3664,  1.8418,  0.8283, -0.1000, -0.3923,  0.7472,\n",
       "          0.1295,  1.8983],\n",
       "        [ 0.0748,  0.4837,  1.3895,  1.1097,  0.9346,  0.4411,  1.3153,  1.4955,\n",
       "          1.7193, -0.5116],\n",
       "        [ 1.0799,  0.9741,  1.0923,  0.1332, -1.7702,  1.8441,  0.0563,  0.9300,\n",
       "          0.5956, -0.0144],\n",
       "        [ 1.1667,  1.5886, -0.1969,  1.2411, -0.4864, -0.7643,  0.8716,  0.3799,\n",
       "          1.6705, -0.1638],\n",
       "        [ 0.5684, -0.1317,  1.6773,  0.5819,  0.5804,  0.8921,  0.1759,  1.3960,\n",
       "          1.6376, -0.1045],\n",
       "        [ 0.8273,  0.8742,  1.0750, -0.6847,  0.1277,  0.7444,  1.4810,  1.5657,\n",
       "         -0.8013,  0.3618],\n",
       "        [ 1.1269, -0.0420,  0.0054,  1.2573, -0.2615,  1.8038,  1.7070,  0.4530,\n",
       "          1.4501, -0.7431],\n",
       "        [ 1.1692,  0.8024,  1.6221,  1.5243, -1.4324,  0.9368,  1.1536,  0.1106,\n",
       "          1.6128,  1.0403],\n",
       "        [ 0.2571,  1.0266, -0.2948, -0.1377,  0.6179, -0.2333,  0.4565, -0.0430,\n",
       "         -0.2859,  0.1771],\n",
       "        [ 1.7509,  0.7021, -0.5918, -0.2597, -0.6675, -0.5234,  1.6620, -0.7441,\n",
       "          0.7859, -0.0933]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decorator\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "\n",
    "    return a + b\n",
    "\n",
    "opt_foo2(torch.randn(10, 10, device = 'cuda'), torch.randn(10, 10, device = 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba5f9f1c-b8dc-4d98-92c3-1fc80f7162d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4975, 0.8017, 0.2126, 0.8430, 0.0000, 0.3458, 0.0000, 0.1168, 0.5510,\n",
       "         0.4983],\n",
       "        [0.0000, 0.7382, 0.3635, 0.0000, 0.0000, 0.0000, 0.7001, 0.0000, 0.0000,\n",
       "         0.8859],\n",
       "        [0.3452, 0.7900, 0.0000, 0.4961, 0.0739, 0.8515, 1.3017, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.6337, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0925, 0.2047,\n",
       "         0.0000],\n",
       "        [0.0000, 0.9721, 0.0000, 0.0000, 0.2128, 0.0000, 0.0000, 0.9190, 0.5621,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0832, 0.0000, 0.0000, 0.1821, 0.5651, 0.0000, 0.8072, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7612, 0.2724, 0.2608, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0564, 0.0000, 1.0035, 0.9434, 0.7710, 0.0000, 0.1910, 0.0000, 0.0000,\n",
       "         0.4188],\n",
       "        [0.4641, 0.0000, 0.0000, 0.0000, 0.2236, 0.1572, 0.0000, 1.2034, 0.2231,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.3015, 0.1333, 0.0000, 0.4584,\n",
       "         0.1859]], grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using with nn.Module\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(100, 10)\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.lin(x))\n",
    "\n",
    "mod = MyModule()\n",
    "opt_mod = torch.compile(mod)\n",
    "\n",
    "opt_mod(torch.randn(10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14c6cec6-9e52-41cd-98a3-2afa0fe7f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed up Benchmarking\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "def generate(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 182).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b, )).cuda()\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fb709e6-3ac5-49f2-8d47-884c2cdfbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "torch.set_float32_matmul_precision('high') # recommended, try running without this\n",
    "\n",
    "model_opt = torch.compile(model, mode = 'reduce-overhead', fullgraph=True)\n",
    "\n",
    "inp = generate(16)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d1a0a47-2c3d-46ef-951e-3de87c234ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager: 0.012969842910766602\n",
      "Compile: 0.008802530288696288\n"
     ]
    }
   ],
   "source": [
    "# run this 3-4 times to see the spped-up\n",
    "# It takes soem time initially for the model to get compiled\n",
    "with torch.no_grad():\n",
    "    print(f\"Eager: {timed(lambda: model(inp))[1]}\")\n",
    "    print(f\"Compile: {timed(lambda: model_opt(inp))[1]}\")\n",
    "\n",
    "# default ~ 0.013765316009521484\n",
    "# reduce-overhead ~ 0.008926656723022461\n",
    "# max-autotune ~ 0.00884480857849121 (not sure as the size caused SM availability issue for bs 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b15ac99e-1f65-4546-ba6e-1d9de50c06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager train time 0: 0.04989938354492188\n",
      "eager train time 1: 0.0439447021484375\n",
      "eager train time 2: 0.041905353546142575\n",
      "eager train time 3: 0.0423111457824707\n",
      "eager train time 4: 0.04173397064208984\n",
      "eager train time 5: 0.042759727478027344\n",
      "eager train time 6: 0.04166627883911133\n",
      "eager train time 7: 0.04206362533569336\n",
      "eager train time 8: 0.04154611968994141\n",
      "eager train time 9: 0.04225003051757813\n",
      "~~~~~~~~~~\n",
      "compile train time 0: 55.28408984375\n",
      "compile train time 1: 3.685318359375\n",
      "compile train time 2: 0.03765531921386719\n",
      "compile train time 3: 0.030465112686157227\n",
      "compile train time 4: 0.030319047927856446\n",
      "compile train time 5: 0.030236528396606444\n",
      "compile train time 6: 0.029931007385253908\n",
      "compile train time 7: 0.030063478469848633\n",
      "compile train time 8: 0.029744375228881837\n",
      "compile train time 9: 0.029800947189331056\n",
      "~~~~~~~~~~\n",
      "compile train time 0: 31.219828125\n",
      "compile train time 1: 1.7047236328125\n",
      "compile train time 2: 0.03246184158325195\n",
      "compile train time 3: 0.03068179130554199\n",
      "compile train time 4: 0.030700311660766602\n",
      "compile train time 5: 0.03061949157714844\n",
      "compile train time 6: 0.03021546745300293\n",
      "compile train time 7: 0.03026173973083496\n",
      "compile train time 8: 0.030047798156738283\n",
      "compile train time 9: 0.030014368057250978\n",
      "~~~~~~~~~~\n",
      "(train) eager median: 0.04215682792663575, compile median: 0.030277788162231443, speedup: 1.392335123713635x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# Training benchmark\n",
    "import numpy as np\n",
    "\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train(mod, data):\n",
    "    opt.zero_grad(True)\n",
    "    pred = mod(data[0])\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, data[1])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate(16)\n",
    "    _, eager_time = timed(lambda: train(model, inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager train time {i}: {eager_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_opt = torch.compile(train, mode=\"reduce-overhead\")\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate(16)\n",
    "    _, compile_time = timed(lambda: train_opt(model, inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile train time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "model_compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate(16)\n",
    "    _, compile_time = timed(lambda: train(model_opt, inp))\n",
    "    model_compile_times.append(compile_time)\n",
    "    print(f\"compile train time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "model_compile_med = np.median(model_compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(train) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d90b27-712e-4ffe-a0f8-e03f937d8d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061abf6-16a5-4b42-91c1-38b8a2a7e041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
