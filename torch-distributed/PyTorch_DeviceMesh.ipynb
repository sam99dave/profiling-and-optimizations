{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Why DeviceMesh?\n",
        "\n",
        "Setting up distributed communicators such as `NCCL` (Nvidia Collective Communication Library) communicators, for distributed training can pose a significant challenge.\n",
        "\n",
        "User may need to manually set up and manage NCCL communicators (e.g. ProcessGroup) for each parallelism solution. This can cause a lot of headache if the workload is composed of different parallelisms.\n",
        "\n",
        "Moreover, due to the manual nature it is susceptible to errors.\n",
        "\n",
        "`DeviceMesh` can simplify this process, making it more manageable and less prone to errors.\n",
        "\n",
        "### What is a DeviceMesh?\n",
        "\n",
        "Its a higher level abstraction that manages the `ProcessGroup`\n",
        "\n",
        "- Easy setup of intra & inter nodes\n",
        "- No worry about the rank setup for each subgroup\n",
        "\n",
        "### Use\n",
        "\n",
        "DeviceMesh is useful when working with multiple dimensional parallelism (i.e. 3D parallel), here parallelism composability is required.\n",
        "- Parallelism solution that requires both communication across host and within each host.\n",
        "\n",
        "E.g. If there are 2 host machines and each host machine has 2 GPUs.\n",
        "\n",
        "Over here, without DeviceMesh the user will have to manually setup the NCCL communicators, cuda devices on each process before applying any parallelism, which is complicated and cause manual errors."
      ],
      "metadata": {
        "id": "YVVwZnku76Qw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vulFJAE83p2w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['RANK'] = '0'\n",
        "os.environ['WORLD_SIZE'] = '1'\n",
        "os.environ['MASTER_ADDR'] = 'localhost'  # Replace with your master address if distributed across machines\n",
        "os.environ['MASTER_PORT'] = '12345'"
      ],
      "metadata": {
        "id": "BHGpZCAdITh5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below script using torchrun\n",
        "\n",
        "```bash\n",
        "torchrun --nproc_per_node=8 --rdzv_id=100 --rdzv_endpoint=localhost:29400 2d_setup.py\n",
        "```"
      ],
      "metadata": {
        "id": "v8m0bngQKC6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK THIS OUT IN KAGGLE NOTEBOOK, 2 GPUS\n",
        "# WILL FAIL IN COLAB UNLESS THE SHARD RANK LIST IS SET FOR 1 DEVICE/GPU\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "# Understand world topology\n",
        "rank = int(os.environ[\"RANK\"])\n",
        "world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "print(f\"Running example on {rank=} in a world with {world_size=}\")\n",
        "\n",
        "# Create process groups to manage 2-D like parallel pattern\n",
        "dist.init_process_group(\"nccl\")\n",
        "torch.cuda.set_device(rank)\n",
        "\n",
        "# Create shard groups (e.g. (0, 1, 2, 3), (4, 5, 6, 7))\n",
        "# and assign the correct shard group to each rank\n",
        "num_node_devices = torch.cuda.device_count()\n",
        "shard_rank_lists = list(range(0, num_node_devices // 2)), list(range(num_node_devices // 2, num_node_devices))\n",
        "shard_groups = (\n",
        "    dist.new_group(shard_rank_lists[0]),\n",
        "    dist.new_group(shard_rank_lists[1]),\n",
        ")\n",
        "current_shard_group = (\n",
        "    shard_groups[0] if rank in shard_rank_lists[0] else shard_groups[1]\n",
        ")\n",
        "\n",
        "# Create replicate groups (for example, (0, 4), (1, 5), (2, 6), (3, 7))\n",
        "# and assign the correct replicate group to each rank\n",
        "current_replicate_group = None\n",
        "shard_factor = len(shard_rank_lists[0])\n",
        "for i in range(num_node_devices // 2):\n",
        "    replicate_group_ranks = list(range(i, num_node_devices, shard_factor))\n",
        "    replicate_group = dist.new_group(replicate_group_ranks)\n",
        "    if rank in replicate_group_ranks:\n",
        "        current_replicate_group = replicate_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "collapsed": true,
        "id": "-RCFwszPJBhK",
        "outputId": "b6e1f9b4-4d14-462a-c905-f524b7cea490"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running example on rank=0 in a world with world_size=1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "__init__(): incompatible constructor arguments. The following argument types are supported:\n    1. torch._C._distributed_c10d.ProcessGroup(arg0: int, arg1: int)\n    2. torch._C._distributed_c10d.ProcessGroup(arg0: torch._C._distributed_c10d.Store, arg1: int, arg2: int, arg3: c10d::ProcessGroup::Options)\n\nInvoked with: <torch.distributed.distributed_c10d.PrefixStore object at 0x78955ad69bb0>, None, 0, <torch._C._distributed_c10d.ProcessGroup.Options object at 0x789559921bb0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5af6cbad396f>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mshard_rank_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_node_devices\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_node_devices\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_node_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m shard_groups = (\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_rank_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_rank_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfunc_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mnew_group\u001b[0;34m(ranks, timeout, backend, pg_options, use_local_synchronization)\u001b[0m\n\u001b[1;32m   3866\u001b[0m     \u001b[0msame\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0mcreation\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3867\u001b[0m     \"\"\"\n\u001b[0;32m-> 3868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_new_group_with_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpg_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_local_synchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_local_synchronization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3870\u001b[0m def _new_group_with_tag(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_new_group_with_tag\u001b[0;34m(ranks, timeout, backend, pg_options, pg_tag, use_local_synchronization)\u001b[0m\n\u001b[1;32m   3937\u001b[0m     \u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_group_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_hashed_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_local_synchronization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3939\u001b[0;31m     pg, pg_store = _new_process_group_helper(\n\u001b[0m\u001b[1;32m   3940\u001b[0m         \u001b[0mgroup_world_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3941\u001b[0m         \u001b[0mgroup_rank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_new_process_group_helper\u001b[0;34m(group_size, group_rank, global_ranks_in_group, backend, store, group_name, pg_options, timeout, pg_tag, device_id)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0mbase_pg_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0mbase_pg_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m     \u001b[0mpg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mProcessGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_pg_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound_device_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__(): incompatible constructor arguments. The following argument types are supported:\n    1. torch._C._distributed_c10d.ProcessGroup(arg0: int, arg1: int)\n    2. torch._C._distributed_c10d.ProcessGroup(arg0: torch._C._distributed_c10d.Store, arg1: int, arg2: int, arg3: c10d::ProcessGroup::Options)\n\nInvoked with: <torch.distributed.distributed_c10d.PrefixStore object at 0x78955ad69bb0>, None, 0, <torch._C._distributed_c10d.ProcessGroup.Options object at 0x789559921bb0>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below script using torchrun as follows, add the code to a file with specified filename\n",
        "\n",
        "\n",
        "```bash\n",
        "torchrun --nproc_per_node=8 2d_setup_with_device_mesh.py\n",
        "```"
      ],
      "metadata": {
        "id": "Iz45vi68KRFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## THIS WON't WORK ON KAGGLE, SOME PYTORCH VERSION ISSUE\n",
        "## `device_mesh` not found error\n",
        "## WORKS WELL WITH COLAB, JUST KEEP THE MESH SIZE FOR 1 GPU i.e (1,1)\n",
        "## IF INCASE OF 8 GPU SPLIT IN 2 SHARDS THEN IT WILL BE (2, 4)\n",
        "\n",
        "from torch.distributed.device_mesh import init_device_mesh\n",
        "mesh_2d = init_device_mesh(\"cuda\", (1,1), mesh_dim_names=(\"replicate\", \"shard\"))\n",
        "\n",
        "# Users can access the underlying process group thru `get_group` API.\n",
        "replicate_group = mesh_2d.get_group(mesh_dim=\"replicate\")\n",
        "shard_group = mesh_2d.get_group(mesh_dim=\"shard\")"
      ],
      "metadata": {
        "id": "qojohd1V4J24"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replicate_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gWq8iPUIPP2",
        "outputId": "fbc5c9cf-d41f-4824-f3f6-3935dbfad30d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.distributed.distributed_c10d.ProcessGroup at 0x7b9e74970c70>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shard_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvNq276xIcmx",
        "outputId": "b1543edb-f976-41fb-e90b-ecc2a081c98a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.distributed.distributed_c10d.ProcessGroup at 0x7b9e749727f0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using DeviceMesh with HSDP\n",
        "\n",
        "HSDP - Hybrid Sharding Data Parallel\n",
        "\n",
        "Its a 2D strategy to perform FSDP within a host and DDP across hosts\n",
        "\n",
        "\n",
        "```bash\n",
        "torchrun --nproc_per_node=8 hsdp.py\n",
        "```\n"
      ],
      "metadata": {
        "id": "gda1uvTcKfK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributed.device_mesh import init_device_mesh\n",
        "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP, ShardingStrategy"
      ],
      "metadata": {
        "id": "TPJD1LQ5IeHR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.net1 = nn.Linear(10, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.net2 = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net2(self.relu(self.net1(x)))\n",
        "\n",
        "# HSDP: MeshShape(2, 4)\n",
        "mesh_2d = init_device_mesh(\"cuda\", (1, 1))\n",
        "model = FSDP(\n",
        "    ToyModel(), device_mesh=mesh_2d, sharding_strategy=ShardingStrategy.HYBRID_SHARD\n",
        ")\n",
        "\n",
        "## NOT A GOOD EXAMPLE, AS SINGLE MACHINE SINGLE GPU\n",
        "## (2, 4) ALSO FOR A GOOD USE SHOULD BE I THINK 2 HOSTS WITH 4 GPUS EACH\n",
        "## INSTEAD OF A SINGLE MACHINE WITH 8 GPUS AS THE DDP WILL BE WITHIN HOST ONLY"
      ],
      "metadata": {
        "id": "9bTSElUWLJXl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}