{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f69108e-9062-494c-a200-fcbc260d6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to ``bmm``'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)\n",
    "\n",
    "\n",
    "# Input for benchmarking\n",
    "x = torch.randn(10000, 64)\n",
    "\n",
    "# Ensure that both functions compute the same output\n",
    "assert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5e6da3-3f5f-4d0b-8533-44fc5d1defff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 64])\n",
      "torch.Size([10000, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.reshape(-1, 1, x.shape[-1]).shape)\n",
    "print(x.reshape(-1, x.shape[-1], 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbc579-6e22-428c-9349-adde775edc92",
   "metadata": {},
   "source": [
    "### Using `timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc67e30c-9b69-4c0e-be8f-c51f06305b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):   38.7 us\n",
      "bmm(x, x):       76.8 us\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cc1b3-e1db-440c-b7d6-47f0246537c3",
   "metadata": {},
   "source": [
    "### Using PyTorch Benchmark\n",
    "\n",
    "- benchmark.Timer.timeit() returns the time per run as opposed to the total runtime like timeit.Timer.timeit() does.\n",
    "- PyTorch benchmark module also provides formatted string representations for printing the results.\n",
    "- Another important difference, and the reason why the results diverge is that PyTorch benchmark module runs in a `single thread by default`. We can change the number of threads with the num_threads argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb5758d-4b9b-498d-b79e-ea4afb2f64c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183f33a0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  106.82 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183f2e30>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  364.75 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fbb4bd-561c-45cb-9763-5ddb09c02c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on 8 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183af7c0>\n",
      "Multithreaded batch dot: Implemented using mul and sum\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  23.19 us\n",
      "  1 measurement, 100 runs , 8 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1fba1262f0>\n",
      "Multithreaded batch dot: Implemented using bmm\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  60.78 us\n",
      "  1 measurement, 100 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "num_threads = torch.get_num_threads()\n",
    "print(f'Benchmarking on {num_threads} threads')\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using mul and sum')\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using bmm')\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848584e-baab-488d-a41f-f8d43650b7d7",
   "metadata": {},
   "source": [
    "### Benchmarking on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbc6da7-2cde-431a-9162-35921df3484b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):  176.0 us\n",
      "mul_sum(x, x):    7.8 us\n",
      "bmm(x, x):      2546.3 us\n",
      "bmm(x, x):       11.1 us\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10000, 1024, device='cuda')\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Ran each twice to show difference before/after warm-up\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72738885-1128-4d01-a5d3-be3a3792fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1febd66fb0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  111.67 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183f3610>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  845.03 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Run only once since benchmark module does warm-up for us\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81288fa0-a3e3-4359-823f-8a72931a344d",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "The first run of the bmm version using the timeit module takes much longer than the second run.\n",
    "This is because bmm calls into `cuBLAS` which needs to be loaded the first time it’s called which takes some time. \n",
    "This is why it’s important to do a `warm-up` run before benchmarking, luckily for us, PyTorch’s benchmark module takes care of that.\n",
    "\n",
    "The difference in the results between timeit and benchmark modules is because \n",
    "the timeit module is not `synchronizing CUDA` and is thus only timing the time to launch the kernel. \n",
    "PyTorch’s benchmark module does the synchronization for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda5bbe-a286-4cea-a268-f78d9302ad3f",
   "metadata": {},
   "source": [
    "### Using `Blocked Autotrange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8e825b-5487-4fbd-8950-18b03e6c8494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183f36a0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  Median: 66.76 us\n",
      "  IQR:    0.37 us (66.56 to 66.94)\n",
      "  4 measurements, 1000 runs per measurement, 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f23183f2ce0>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  Median: 774.04 us\n",
      "  3 measurements, 100 runs per measurement, 1 thread\n"
     ]
    }
   ],
   "source": [
    "m0 = t0.blocked_autorange()\n",
    "m1 = t1.blocked_autorange()\n",
    "\n",
    "print(m0)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73bdde0-39e4-4b11-8905-5602f3af8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:    66.74 us\n",
      "Median:  66.76 us\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean:   {m0.mean * 1e6:6.2f} us\")\n",
    "print(f\"Median: {m0.median * 1e6:6.2f} us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701fba5-8aff-4fb3-b6f7-ef367c20e742",
   "metadata": {},
   "source": [
    "### Comparing Benchmark Results\n",
    "\n",
    "Over different inputs & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5295a8d0-8811-4e28-863c-3818b99fdec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------- Batched dot ---------------]\n",
      "                      |  mul/sum   |    bmm  \n",
      "1 threads: ----------------------------------\n",
      "      [1, 1]          |       2.4  |      3.9\n",
      "      [1, 64]         |       2.4  |      3.9\n",
      "      [1, 1024]       |       2.5  |      4.1\n",
      "      [1, 10000]      |       3.3  |      4.8\n",
      "      [64, 1]         |       2.5  |      4.1\n",
      "      [64, 64]        |       3.1  |      6.0\n",
      "      [64, 1024]      |       8.3  |     59.0\n",
      "      [64, 10000]     |      65.3  |    542.4\n",
      "      [1024, 1]       |       2.8  |      7.1\n",
      "      [1024, 64]      |      10.7  |     37.2\n",
      "      [1024, 1024]    |     108.7  |    888.1\n",
      "      [1024, 10000]   |   12489.0  |   8594.7\n",
      "      [10000, 1]      |       6.0  |     34.2\n",
      "      [10000, 64]     |      88.1  |    332.2\n",
      "      [10000, 1024]   |   12395.3  |   8600.6\n",
      "      [10000, 10000]  |  140360.1  |  84263.4\n",
      "2 threads: ----------------------------------\n",
      "      [1, 1]          |       2.3  |      3.9\n",
      "      [1, 64]         |       2.4  |      3.9\n",
      "      [1, 1024]       |       2.5  |      4.1\n",
      "      [1, 10000]      |       3.3  |      4.8\n",
      "      [64, 1]         |       2.5  |      4.1\n",
      "      [64, 64]        |       3.1  |      6.0\n",
      "      [64, 1024]      |       7.2  |     32.4\n",
      "      [64, 10000]     |      37.9  |    276.5\n",
      "      [1024, 1]       |       2.8  |      7.1\n",
      "      [1024, 64]      |       8.6  |     21.6\n",
      "      [1024, 1024]    |      61.5  |    451.7\n",
      "      [1024, 10000]   |    7232.7  |   4319.7\n",
      "      [10000, 1]      |       6.0  |     34.1\n",
      "      [10000, 64]     |      49.0  |    173.3\n",
      "      [10000, 1024]   |    7268.2  |   4320.1\n",
      "      [10000, 10000]  |   88062.1  |  42700.3\n",
      "4 threads: ----------------------------------\n",
      "      [1, 1]          |       2.3  |      3.9\n",
      "      [1, 64]         |       2.4  |      3.9\n",
      "      [1, 1024]       |       2.5  |      4.1\n",
      "      [1, 10000]      |       3.4  |      4.8\n",
      "      [64, 1]         |       2.5  |      4.1\n",
      "      [64, 64]        |       3.1  |      6.0\n",
      "      [64, 1024]      |      11.7  |     18.8\n",
      "      [64, 10000]     |      23.1  |    141.9\n",
      "      [1024, 1]       |       2.8  |      7.1\n",
      "      [1024, 64]      |      12.0  |     21.8\n",
      "      [1024, 1024]    |      34.2  |    230.1\n",
      "      [1024, 10000]   |    4563.1  |   2188.9\n",
      "      [10000, 1]      |       6.0  |     34.1\n",
      "      [10000, 64]     |      29.1  |     88.7\n",
      "      [10000, 1024]   |    4577.6  |   2185.1\n",
      "      [10000, 10000]  |   62634.9  |  21474.1\n",
      "8 threads: ----------------------------------\n",
      "      [1, 1]          |       2.3  |      3.9\n",
      "      [1, 64]         |       2.4  |      3.9\n",
      "      [1, 1024]       |       2.5  |      4.1\n",
      "      [1, 10000]      |       3.3  |      4.8\n",
      "      [64, 1]         |       2.5  |      4.1\n",
      "      [64, 64]        |       3.1  |      6.0\n",
      "      [64, 1024]      |      12.3  |     30.4\n",
      "      [64, 10000]     |      12.0  |    244.2\n",
      "      [1024, 1]       |       2.8  |      7.0\n",
      "      [1024, 64]      |      12.7  |     22.0\n",
      "      [1024, 1024]    |      20.3  |    119.2\n",
      "      [1024, 10000]   |    3171.0  |   1103.3\n",
      "      [10000, 1]      |       6.0  |     34.1\n",
      "      [10000, 64]     |      15.7  |     47.4\n",
      "      [10000, 1024]   |    3178.0  |   1118.2\n",
      "      [10000, 10000]  |   60616.3  |  10775.7\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Compare takes a list of measurements which we'll save in results.\n",
    "results = []\n",
    "\n",
    "sizes = [1, 64, 1024, 10000]\n",
    "for b, n in product(sizes, sizes):\n",
    "    # label and sub_label are the rows\n",
    "    # description is the column\n",
    "    label = 'Batched dot'\n",
    "    sub_label = f'[{b}, {n}]'\n",
    "    x = torch.ones((b, n))\n",
    "    for num_threads in [1, 2, 4, 8]:\n",
    "        results.append(benchmark.Timer(\n",
    "            stmt='batched_dot_mul_sum(x, x)',\n",
    "            setup='from __main__ import batched_dot_mul_sum',\n",
    "            globals={'x': x},\n",
    "            num_threads=num_threads,\n",
    "            label=label,\n",
    "            sub_label=sub_label,\n",
    "            description='mul/sum',\n",
    "        ).blocked_autorange(min_run_time=1))\n",
    "        results.append(benchmark.Timer(\n",
    "            stmt='batched_dot_bmm(x, x)',\n",
    "            setup='from __main__ import batched_dot_bmm',\n",
    "            globals={'x': x},\n",
    "            num_threads=num_threads,\n",
    "            label=label,\n",
    "            sub_label=sub_label,\n",
    "            description='bmm',\n",
    "        ).blocked_autorange(min_run_time=1))\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90137d81-81d7-498e-b210-6c3e7b45226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------- Batched dot --------------]\n",
      "                      |  mul/sum  |   bmm \n",
      "1 threads: -------------------------------\n",
      "      [1, 1]          |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 64]         |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 1024]       |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 10000]      |        3  |      5\n",
      "      [64, 1]         |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [64, 64]        |        3  |      6\n",
      "      [64, 1024]      |  \u001b[2m\u001b[91m      8\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   59\u001b[0m\u001b[0m\n",
      "      [64, 10000]     |  \u001b[31m\u001b[1m     70\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  542\u001b[0m\u001b[0m\n",
      "      [1024, 1]       |        3  |      7\n",
      "      [1024, 64]      |  \u001b[2m\u001b[91m     11\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   37\u001b[0m\u001b[0m\n",
      "      [1024, 1024]    |  \u001b[31m\u001b[1m    100\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  888\u001b[0m\u001b[0m\n",
      "      [1024, 10000]   |  \u001b[31m\u001b[1m  12500\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 8590\u001b[0m\u001b[0m\n",
      "      [10000, 1]      |  \u001b[2m\u001b[91m      6\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   34\u001b[0m\u001b[0m\n",
      "      [10000, 64]     |  \u001b[31m\u001b[1m     88\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  332\u001b[0m\u001b[0m\n",
      "      [10000, 1024]   |  \u001b[31m\u001b[1m  12000\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 8600\u001b[0m\u001b[0m\n",
      "      [10000, 10000]  |  \u001b[31m\u001b[1m 140000\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m84300\u001b[0m\u001b[0m\n",
      "2 threads: -------------------------------\n",
      "      [1, 1]          |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 64]         |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 1024]       |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 10000]      |        3  |      5\n",
      "      [64, 1]         |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [64, 64]        |        3  |      6\n",
      "      [64, 1024]      |  \u001b[2m\u001b[91m      7\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   32\u001b[0m\u001b[0m\n",
      "      [64, 10000]     |  \u001b[31m\u001b[1m     38\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  276\u001b[0m\u001b[0m\n",
      "      [1024, 1]       |        3  |      7\n",
      "      [1024, 64]      |  \u001b[2m\u001b[91m      9\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   22\u001b[0m\u001b[0m\n",
      "      [1024, 1024]    |  \u001b[31m\u001b[1m     61\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  452\u001b[0m\u001b[0m\n",
      "      [1024, 10000]   |  \u001b[31m\u001b[1m   7230\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 4320\u001b[0m\u001b[0m\n",
      "      [10000, 1]      |  \u001b[2m\u001b[91m      6\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   34\u001b[0m\u001b[0m\n",
      "      [10000, 64]     |  \u001b[31m\u001b[1m     49\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  173\u001b[0m\u001b[0m\n",
      "      [10000, 1024]   |  \u001b[31m\u001b[1m   7270\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 4320\u001b[0m\u001b[0m\n",
      "      [10000, 10000]  |  \u001b[31m\u001b[1m  88000\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m42700\u001b[0m\u001b[0m\n",
      "4 threads: -------------------------------\n",
      "      [1, 1]          |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 64]         |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 1024]       |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 10000]      |        3  |      5\n",
      "      [64, 1]         |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [64, 64]        |        3  |      6\n",
      "      [64, 1024]      |  \u001b[31m\u001b[1m     12\u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m   19\u001b[0m\u001b[0m\n",
      "      [64, 10000]     |  \u001b[31m\u001b[1m     20\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  140\u001b[0m\u001b[0m\n",
      "      [1024, 1]       |        3  |      7\n",
      "      [1024, 64]      |  \u001b[31m\u001b[1m     12\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   22\u001b[0m\u001b[0m\n",
      "      [1024, 1024]    |  \u001b[31m\u001b[1m     34\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  230\u001b[0m\u001b[0m\n",
      "      [1024, 10000]   |  \u001b[31m\u001b[1m   4560\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 2190\u001b[0m\u001b[0m\n",
      "      [10000, 1]      |  \u001b[2m\u001b[91m      6\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   34\u001b[0m\u001b[0m\n",
      "      [10000, 64]     |  \u001b[31m\u001b[1m     29\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   89\u001b[0m\u001b[0m\n",
      "      [10000, 1024]   |  \u001b[31m\u001b[1m   4600\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 2190\u001b[0m\u001b[0m\n",
      "      [10000, 10000]  |  \u001b[31m\u001b[1m  63000\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m21470\u001b[0m\u001b[0m\n",
      "8 threads: -------------------------------\n",
      "      [1, 1]          |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 64]         |  \u001b[92m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 1024]       |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [1, 10000]      |        3  |      5\n",
      "      [64, 1]         |  \u001b[34m\u001b[1m      2\u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m    4\u001b[0m\u001b[0m\n",
      "      [64, 64]        |        3  |      6\n",
      "      [64, 1024]      |  \u001b[31m\u001b[1m     12\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   30\u001b[0m\u001b[0m\n",
      "      [64, 10000]     |  \u001b[31m\u001b[1m     12\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  240\u001b[0m\u001b[0m\n",
      "      [1024, 1]       |        3  |      7\n",
      "      [1024, 64]      |  \u001b[31m\u001b[1m     13\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   22\u001b[0m\u001b[0m\n",
      "      [1024, 1024]    |  \u001b[31m\u001b[1m     20\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  119\u001b[0m\u001b[0m\n",
      "      [1024, 10000]   |  \u001b[31m\u001b[1m   3170\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 1100\u001b[0m\u001b[0m\n",
      "      [10000, 1]      |  \u001b[2m\u001b[91m      6\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   34\u001b[0m\u001b[0m\n",
      "      [10000, 64]     |  \u001b[31m\u001b[1m     16\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   47\u001b[0m\u001b[0m\n",
      "      [10000, 1024]   |  \u001b[31m\u001b[1m   3180\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 1120\u001b[0m\u001b[0m\n",
      "      [10000, 10000]  |  \u001b[31m\u001b[1m  60600\u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m11000\u001b[0m\u001b[0m\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare.trim_significant_figures()\n",
    "compare.colorize()\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22ba930-ade8-485d-b30e-cfe9878a6b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------- Batched dot -------------------------------------]\n",
      "                                               |  [1, 1]  |  [1024, 10000]  |  [10000, 1]\n",
      "1 threads: ------------------------------------------------------------------------------\n",
      "  (environment A: mul/sum)  batched_dot(x, x)  |  \u001b[92m\u001b[1m  2   \u001b[0m\u001b[0m  |      13000      |  \u001b[92m\u001b[1m    6.0   \u001b[0m\u001b[0m\n",
      "  (environment B: bmm)      batched_dot(x, x)  |    4     |  \u001b[92m\u001b[1m     8410    \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m   34.1   \u001b[0m\u001b[0m\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ab_test_results = []\n",
    "for env in ('environment A: mul/sum', 'environment B: bmm'):\n",
    "    for b, n in ((1, 1), (1024, 10000), (10000, 1)):\n",
    "        x = torch.ones((b, n))\n",
    "        dot_fn = (batched_dot_mul_sum if env == 'environment A: mul/sum' else batched_dot_bmm)\n",
    "        m = benchmark.Timer(\n",
    "            stmt='batched_dot(x, x)',\n",
    "            globals={'x': x, 'batched_dot': dot_fn},\n",
    "            num_threads=1,\n",
    "            label='Batched dot',\n",
    "            description=f'[{b}, {n}]',\n",
    "            env=env,\n",
    "        ).blocked_autorange(min_run_time=1)\n",
    "        ab_test_results.append(pickle.dumps(m))\n",
    "\n",
    "ab_results = [pickle.loads(i) for i in ab_test_results]\n",
    "compare = benchmark.Compare(ab_results)\n",
    "compare.trim_significant_figures()\n",
    "compare.colorize()\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26956505-d238-4aa1-8930-17b6ff90c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And just to show that we can round trip all of the results from earlier:\n",
    "round_tripped_results = pickle.loads(pickle.dumps(results))\n",
    "assert(str(benchmark.Compare(results)) == str(benchmark.Compare(round_tripped_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f999b-26f6-4e17-98d0-aaa319492ec3",
   "metadata": {},
   "source": [
    "### Fuzzed Parameters ( Generating inputs - automating input generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996d63cd-a4b9-4712-8bd8-08a318d37610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------- Batched dot ---------------------]\n",
      "                                     |  mul/sum  |   bmm \n",
      "1 threads: ----------------------------------------------\n",
      "      725    x 257                   |     30    |    116\n",
      "      49     x 383                   |      4    |     15\n",
      "      34     x 1468                  |      7    |     46\n",
      "      187    x 5039                  |    100    |    793\n",
      "      2140   x 1296 (discontiguous)  |    300    |  10900\n",
      "      78     x 1598                  |     16    |    108\n",
      "      519    x 763                   |     44    |    338\n",
      "      141    x 1082                  |     20    |    130\n",
      "      78     x 5    (discontiguous)  |      3    |      6\n",
      "      187    x 1                     |      3    |      4\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.benchmark import Fuzzer, FuzzedParameter, FuzzedTensor, ParameterAlias\n",
    "\n",
    "# Generates random tensors with 128 to 10000000 elements and sizes k0 and k1 chosen from a\n",
    "# ``loguniform`` distribution in [1, 10000], 40% of which will be discontiguous on average.\n",
    "example_fuzzer = Fuzzer(\n",
    "    parameters = [\n",
    "        FuzzedParameter('k0', minval=1, maxval=10000, distribution='loguniform'),\n",
    "        FuzzedParameter('k1', minval=1, maxval=10000, distribution='loguniform'),\n",
    "    ],\n",
    "    tensors = [\n",
    "        FuzzedTensor('x', size=('k0', 'k1'), min_elements=128, max_elements=10000000, probability_contiguous=0.6)\n",
    "    ],\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "results = []\n",
    "for tensors, tensor_params, params in example_fuzzer.take(10):\n",
    "    # description is the column label\n",
    "    sub_label=f\"{params['k0']:<6} x {params['k1']:<4} {'' if tensor_params['x']['is_contiguous'] else '(discontiguous)'}\"\n",
    "    results.append(benchmark.Timer(\n",
    "        stmt='batched_dot_mul_sum(x, x)',\n",
    "        setup='from __main__ import batched_dot_mul_sum',\n",
    "        globals=tensors,\n",
    "        label='Batched dot',\n",
    "        sub_label=sub_label,\n",
    "        description='mul/sum',\n",
    "    ).blocked_autorange(min_run_time=1))\n",
    "    results.append(benchmark.Timer(\n",
    "        stmt='batched_dot_bmm(x, x)',\n",
    "        setup='from __main__ import batched_dot_bmm',\n",
    "        globals=tensors,\n",
    "        label='Batched dot',\n",
    "        sub_label=sub_label,\n",
    "        description='bmm',\n",
    "    ).blocked_autorange(min_run_time=1))\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.trim_significant_figures()\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c110abc5-2827-4302-840c-d26d66147ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------- Batched dot ------------------------]\n",
      "                                         |  mul/sum  |   bmm  \n",
      "1 threads: ---------------------------------------------------\n",
      "      64     x 473  (discontiguous)      |  \u001b[92m\u001b[1m  4000 \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24000\u001b[0m\u001b[0m\n",
      "      16384  x 12642115 (discontiguous)  |  \u001b[92m\u001b[1m     9 \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m    34\u001b[0m\u001b[0m\n",
      "      8192   x 892                       |  \u001b[92m\u001b[1m   760 \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  6100\u001b[0m\u001b[0m\n",
      "      512    x 64   (discontiguous)      |  \u001b[92m\u001b[1m 33000 \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m123000\u001b[0m\u001b[0m\n",
      "      493    x 27   (discontiguous)      |  \u001b[92m\u001b[1m   357 \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m   873\u001b[0m\u001b[0m\n",
      "      118    x 32   (discontiguous)      |  \u001b[92m\u001b[1m   211 \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m  1060\u001b[0m\u001b[0m\n",
      "      16     x 495  (discontiguous)      |  \u001b[92m\u001b[1m  1900 \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8890\u001b[0m\u001b[0m\n",
      "      488    x 62374                     |   40300   |  \u001b[92m\u001b[1m 25300\u001b[0m\u001b[0m\n",
      "      240372 x 69                        |  \u001b[2m\u001b[91m 22000 \u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m  8530\u001b[0m\u001b[0m\n",
      "      40156  x 32   (discontiguous)      |  \u001b[92m\u001b[1m   310 \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m   940\u001b[0m\u001b[0m\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Built-in Fuzzers\n",
    "\n",
    "from torch.utils.benchmark.op_fuzzers import binary\n",
    "\n",
    "results = []\n",
    "for tensors, tensor_params, params in binary.BinaryOpFuzzer(seed=0).take(10):\n",
    "    sub_label=f\"{params['k0']:<6} x {params['k1']:<4} {'' if tensor_params['x']['is_contiguous'] else '(discontiguous)'}\"\n",
    "    results.append(benchmark.Timer(\n",
    "        stmt='batched_dot_mul_sum(x, x)',\n",
    "        setup='from __main__ import batched_dot_mul_sum',\n",
    "        globals=tensors,\n",
    "        label='Batched dot',\n",
    "        sub_label=sub_label,\n",
    "        description='mul/sum',\n",
    "    ).blocked_autorange(min_run_time=1))\n",
    "    results.append(benchmark.Timer(\n",
    "        stmt='batched_dot_bmm(x, x)',\n",
    "        setup='from __main__ import batched_dot_bmm',\n",
    "        globals=tensors,\n",
    "        label='Batched dot',\n",
    "        sub_label=sub_label,\n",
    "        description='bmm',\n",
    "    ).blocked_autorange(min_run_time=1))\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.trim_significant_figures()\n",
    "compare.colorize(rowwise=True)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d8924-f2df-40bd-8934-9c4d25db86f0",
   "metadata": {},
   "source": [
    "### Collecting Instruction Counts with `Callgrind`\n",
    "\n",
    "One of the challenges of optimizing code is the variation and opacity of wall time. Furthermore, end-to-end time gives no insight into where time is being spent, which is really what we’re interested in when optimizing code.\n",
    "\n",
    "A complementary approach is to also collect instruction counts. These counts are a proxy metric and do not capture all aspects of performance (e.g. memory or I/O bound tasks), however they do have several useful properties. Instruction counts are reproducible, insensitive to environmental variation, and offer fine grained insight into where a program is spending cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6279800f-49f7-4175-b5cd-a418822c529b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1fba127eb0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup:\n",
      "  from __main__ import batched_dot_mul_sum\n",
      "  x = torch.randn(2, 2)\n",
      "\n",
      "  2.22 us\n",
      "  1 measurement, 100000 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1fba127280>\n",
      "cpp_lib.batched_dot_mul_sum_v0(x, x)\n",
      "setup:\n",
      "  import cpp_lib\n",
      "  x = torch.randn(2, 2)\n",
      "\n",
      "  Median: 1.87 us\n",
      "  2 measurements, 100000 runs per measurement, 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1fba127bb0>\n",
      "cpp_lib.batched_dot_mul_sum_v1(x, x)\n",
      "setup:\n",
      "  import cpp_lib\n",
      "  x = torch.randn(2, 2)\n",
      "\n",
      "  Median: 1.81 us\n",
      "  2 measurements, 100000 runs per measurement, 1 thread\n"
     ]
    }
   ],
   "source": [
    "# Implementing using both `reference` & `value`  \n",
    "\n",
    "batched_dot_src = \"\"\"\\\n",
    "/* ---- Python ---- */\n",
    "// def batched_dot_mul_sum(a, b):\n",
    "//     return a.mul(b).sum(-1)\n",
    "\n",
    "torch::Tensor batched_dot_mul_sum_v0(\n",
    "    const torch::Tensor a,\n",
    "    const torch::Tensor b) {\n",
    "  return a.mul(b).sum(-1);\n",
    "}\n",
    "\n",
    "torch::Tensor batched_dot_mul_sum_v1(\n",
    "    const torch::Tensor& a,\n",
    "    const torch::Tensor& b) {\n",
    "  return a.mul(b).sum(-1);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# PyTorch makes it easy to test our C++ implementations by providing a utility\n",
    "# to JIT compile C++ source into Python extensions:\n",
    "import os\n",
    "from torch.utils import cpp_extension\n",
    "cpp_lib = cpp_extension.load_inline(\n",
    "    name='cpp_lib',\n",
    "    cpp_sources=batched_dot_src,\n",
    "    extra_cflags=['-O3'],\n",
    "    extra_include_paths=[\n",
    "        # `load_inline` needs to know where to find ``pybind11`` headers.\n",
    "        # os.path.join(os.getenv('CONDA_PREFIX'), 'include')\n",
    "    ],\n",
    "    functions=['batched_dot_mul_sum_v0', 'batched_dot_mul_sum_v1']\n",
    ")\n",
    "\n",
    "# `load_inline` will create a shared object that is loaded into Python. When we collect\n",
    "# instruction counts Timer will create a subprocess, so we need to re-import it. The\n",
    "# import process is slightly more complicated for C extensions, but that's all we're\n",
    "# doing here.\n",
    "module_import_str = f\"\"\"\\\n",
    "# https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"cpp_lib\", {repr(cpp_lib.__file__)})\n",
    "cpp_lib = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cpp_lib)\"\"\"\n",
    "\n",
    "import textwrap\n",
    "def pretty_print(result):\n",
    "    \"\"\"Import machinery for ``cpp_lib.so`` can get repetitive to look at.\"\"\"\n",
    "    print(repr(result).replace(textwrap.indent(module_import_str, \"  \"), \"  import cpp_lib\"))\n",
    "\n",
    "\n",
    "t_baseline = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='''\\\n",
    "from __main__ import batched_dot_mul_sum\n",
    "x = torch.randn(2, 2)''')\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='cpp_lib.batched_dot_mul_sum_v0(x, x)',\n",
    "    setup=f'''\\\n",
    "{module_import_str}\n",
    "x = torch.randn(2, 2)''')\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='cpp_lib.batched_dot_mul_sum_v1(x, x)',\n",
    "    setup=f'''\\\n",
    "{module_import_str}\n",
    "x = torch.randn(2, 2)''')\n",
    "\n",
    "# Moving to C++ did indeed reduce overhead, but it's hard to tell which\n",
    "# calling convention is more efficient. v1 (call with references) seems to\n",
    "# be a bit faster, but it's within measurement error.\n",
    "pretty_print(t_baseline.blocked_autorange())\n",
    "pretty_print(t0.blocked_autorange())\n",
    "pretty_print(t1.blocked_autorange())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e78739a0-b0e5-440d-9c3d-6456e0860126",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to collect callgrind profile:\nUnknown error.\nvalgrind: python: command not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's use ``Callgrind`` to determine which is better.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stats_v0 \u001b[38;5;241m=\u001b[39m \u001b[43mt0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_callgrind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m stats_v1 \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mcollect_callgrind()\n\u001b[1;32m      5\u001b[0m pretty_print(stats_v0)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/benchmark/utils/timer.py:527\u001b[0m, in \u001b[0;36mTimer.collect_callgrind\u001b[0;34m(self, number, repeats, collect_baseline, retain_out_file)\u001b[0m\n\u001b[1;32m    525\u001b[0m is_python \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_language \u001b[38;5;241m==\u001b[39m Language\u001b[38;5;241m.\u001b[39mPYTHON)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_python \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globals\n\u001b[0;32m--> 527\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalgrind_timer_interface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper_singleton\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_callgrind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollect_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollect_baseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_python\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_python\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_out_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_out_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m repeats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:532\u001b[0m, in \u001b[0;36m_ValgrindWrapper.collect_callgrind\u001b[0;34m(self, task_spec, globals, number, repeats, collect_baseline, is_python, retain_out_file)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_python \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m collect_baseline\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;241m*\u001b[39mtask_stats, baseline_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollect_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollect_baseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_python\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_out_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_out_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(task_stats) \u001b[38;5;241m==\u001b[39m repeats\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    544\u001b[0m     CallgrindStats(\n\u001b[1;32m    545\u001b[0m         task_spec\u001b[38;5;241m=\u001b[39mtask_spec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stmt_inclusive_stats, stmt_exclusive_stats, out_contents \u001b[38;5;129;01min\u001b[39;00m task_stats\n\u001b[1;32m    555\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:665\u001b[0m, in \u001b[0;36m_ValgrindWrapper._invoke\u001b[0;34m(self, task_spec, globals, number, repeats, collect_baseline, is_python, retain_out_file)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error_report:\n\u001b[1;32m    663\u001b[0m         error_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown error.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m valgrind_invocation_output\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to collect callgrind profile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_report\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_output\u001b[39m(fpath: \u001b[38;5;28mstr\u001b[39m, inclusive: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FunctionCounts:\n\u001b[1;32m    668\u001b[0m     annotate_invocation, annotate_invocation_output \u001b[38;5;241m=\u001b[39m run([\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallgrind_annotate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--inclusive=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39minclusive\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m         fpath\n\u001b[1;32m    674\u001b[0m     ], check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to collect callgrind profile:\nUnknown error.\nvalgrind: python: command not found\n"
     ]
    }
   ],
   "source": [
    "# Let's use ``Callgrind`` to determine which is better.\n",
    "stats_v0 = t0.collect_callgrind()\n",
    "stats_v1 = t1.collect_callgrind()\n",
    "\n",
    "pretty_print(stats_v0)\n",
    "pretty_print(stats_v1)\n",
    "\n",
    "# `.as_standardized` removes file names and some path prefixes, and makes\n",
    "# it easier to read the function symbols.\n",
    "stats_v0 = stats_v0.as_standardized()\n",
    "stats_v1 = stats_v1.as_standardized()\n",
    "\n",
    "# `.delta` diffs the instruction counts, and `.denoise` removes several\n",
    "# functions in the Python interpreter that are known to have significant\n",
    "# jitter.\n",
    "delta = stats_v1.delta(stats_v0).denoise()\n",
    "\n",
    "# `.transform` is a convenience API for transforming function names. It is\n",
    "# useful for increasing cancelation when ``diff-ing`` instructions, as well as\n",
    "# just generally improving readability.\n",
    "replacements = (\n",
    "    (\"???:void pybind11\", \"pybind11\"),\n",
    "    (\"batched_dot_mul_sum_v0\", \"batched_dot_mul_sum_v1\"),\n",
    "    (\"at::Tensor, at::Tensor\", \"...\"),\n",
    "    (\"at::Tensor const&, at::Tensor const&\", \"...\"),\n",
    "    (\"auto torch::detail::wrap_pybind_function_impl_\", \"wrap_pybind_function_impl_\"),\n",
    ")\n",
    "for before, after in replacements:\n",
    "    delta = delta.transform(lambda l: l.replace(before, after))\n",
    "\n",
    "# We can use print options to control how much of the function to display.\n",
    "torch.set_printoptions(linewidth=160)\n",
    "\n",
    "# Once parsed, the instruction counts make clear that passing `a` and `b`\n",
    "# by reference is more efficient as it skips some ``c10::TensorImpl`` bookkeeping\n",
    "# for the intermediate Tensors, and is also works better with ``pybind11``. This\n",
    "# is consistent with our noisy wall time observations.\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c962d-3184-4fbb-9efd-d35fb46ae5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Facing issue with `Valgrind`, tried it using script but still didn't work.\n",
    "## TODO:: Figure out `callgrind` workings\n",
    "\n",
    "## By default `load_inline` stores the build in a tmp location. You can set it to be a custom dir ( checkout the .py file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4335a5f-ba39-4d80-9142-53f785fa53da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a9663-d2ec-4a52-83bc-adca8fa202be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
