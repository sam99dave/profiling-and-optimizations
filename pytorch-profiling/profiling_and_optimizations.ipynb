{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Profiling with PyTorch Module\n",
        "\n",
        "**Note**\n",
        "\n",
        "Profiler supports multi-threaded models. Profiler runs in the same thread as the operation but it will also profile child operators that might be running in another thread.\n",
        "\n",
        "In case there are concurrent profilers running then each profiler will be scoped to its thread to prevent the mixing of results."
      ],
      "metadata": {
        "id": "QWo1RaxEP7a_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jpfGWqOtKQk1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize resnet18 & model inputs\n",
        "model = models.resnet18()\n",
        "inputs = torch.randn(5, 3, 244, 244)"
      ],
      "metadata": {
        "id": "lGzFCFvIQ3TP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execution Time Analysis**\n",
        "\n",
        "`activities` - The list of activities to profile\n",
        "\n",
        "- `ProfilerActivity.CPU` - PyTorch operators, TorchScript functions & user-defined code labels\n",
        "- `ProfilerActivity.CUDA` - on device cuda kernels\n",
        "\n",
        "`record_shapes` - whether to record shapes of the operator inputs\n",
        "\n",
        "`profile_memory` - whether to report amount of memory consumed by the model's Tensors\n",
        "\n",
        "`use_cuda` - whether to measure execution time of CUDA kernels"
      ],
      "metadata": {
        "id": "LvlYlI9KRqBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "  with record_function(\"Model Inference\"):\n",
        "    model(inputs)"
      ],
      "metadata": {
        "id": "dNGfUTtgRKOB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITsyPyHnTlnw",
        "outputId": "9ab6f678-b09b-4bcc-ec7b-3f3193e68f2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  Model Inference         2.15%      41.016ms       100.00%        1.910s        1.910s             1  \n",
            "                     aten::conv2d         0.12%       2.351ms        69.75%        1.332s      66.600ms            20  \n",
            "                aten::convolution         0.17%       3.281ms        69.63%        1.330s      66.482ms            20  \n",
            "               aten::_convolution         0.04%     784.000us        69.45%        1.326s      66.318ms            20  \n",
            "         aten::mkldnn_convolution        68.25%        1.303s        69.41%        1.326s      66.279ms            20  \n",
            "                 aten::batch_norm         0.01%     161.000us        13.81%     263.733ms      13.187ms            20  \n",
            "     aten::_batch_norm_impl_index         0.14%       2.675ms        13.80%     263.572ms      13.179ms            20  \n",
            "          aten::native_batch_norm        13.60%     259.769ms        13.66%     260.825ms      13.041ms            20  \n",
            "                 aten::max_pool2d         0.01%     118.000us         9.25%     176.647ms     176.647ms             1  \n",
            "    aten::max_pool2d_with_indices         9.24%     176.529ms         9.24%     176.529ms     176.529ms             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.910s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "The `self CPU` shows the time for the operator. An operator can call multiple operators. `self cpu time` excludes the time spent in children operator calls.\n",
        "\n",
        "`CPU Total` indicates the total time"
      ],
      "metadata": {
        "id": "0OP4pGUwU7kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finer granuler results & include operator shapes\n",
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APtPj4cyT_wd",
        "outputId": "ef5b6107-5ef6-4477-a181-8051f64e275a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                  Model Inference         2.15%      41.016ms       100.00%        1.910s        1.910s             1                                                                                []  \n",
            "                     aten::conv2d         0.00%      73.000us        17.28%     329.987ms      82.497ms             4                             [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], []]  \n",
            "                aten::convolution         0.01%     208.000us        17.28%     329.914ms      82.478ms             4                     [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], [], [], []]  \n",
            "               aten::_convolution         0.01%      96.000us        17.26%     329.706ms      82.427ms             4     [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
            "         aten::mkldnn_convolution        17.25%     329.466ms        17.26%     329.610ms      82.403ms             4                             [[5, 64, 61, 61], [64, 64, 3, 3], [], [], [], [], []]  \n",
            "                     aten::conv2d         0.11%       2.083ms        11.33%     216.452ms     216.452ms             1                             [[5, 3, 244, 244], [64, 3, 7, 7], [], [], [], [], []]  \n",
            "                     aten::conv2d         0.00%      40.000us        11.24%     214.688ms      71.563ms             3                          [[5, 128, 31, 31], [128, 128, 3, 3], [], [], [], [], []]  \n",
            "                aten::convolution         0.01%     107.000us        11.24%     214.648ms      71.549ms             3                  [[5, 128, 31, 31], [128, 128, 3, 3], [], [], [], [], [], [], []]  \n",
            "               aten::_convolution         0.00%      72.000us        11.23%     214.541ms      71.514ms             3  [[5, 128, 31, 31], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
            "         aten::mkldnn_convolution        11.22%     214.334ms        11.23%     214.469ms      71.490ms             3                          [[5, 128, 31, 31], [128, 128, 3, 3], [], [], [], [], []]  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 1.910s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CPU & CUDA Analysis\n",
        "\n",
        "**NOTE**\n",
        "\n",
        "The first profiling of CUDA will bring an extra overhead\n",
        "\n",
        "For Example, running the following cell for the first time results\n",
        "- Self CPU time total: 806.113ms\n",
        "- Self CUDA time total: 10.680ms\n",
        "\n",
        "Then running it again\n",
        "- Self CPU time total: 11.737ms\n",
        "- Self CUDA time total: 10.707ms\n"
      ],
      "metadata": {
        "id": "_vMSSCbzeWph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18().cuda()\n",
        "inputs = torch.randn(5, 3, 244, 244).cuda()\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    record_shapes=True,\n",
        ") as prof:\n",
        "  with record_function(\"model_inference\"):\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAhYiE8cVyWj",
        "outputId": "4581d998-e76c-4b3c-dfd6-afe702b56ec5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        20.47%       2.394ms        80.49%       9.413ms       9.413ms       0.000us         0.00%      10.484ms      10.484ms             1  \n",
            "                                           aten::conv2d         0.86%     100.000us        24.35%       2.848ms     142.400us       0.000us         0.00%       8.347ms     417.350us            20  \n",
            "                                      aten::convolution         2.22%     260.000us        23.50%       2.748ms     137.400us       0.000us         0.00%       8.347ms     417.350us            20  \n",
            "                                     aten::_convolution         1.74%     204.000us        21.27%       2.488ms     124.400us       0.000us         0.00%       8.347ms     417.350us            20  \n",
            "                                aten::cudnn_convolution        15.54%       1.817ms        19.53%       2.284ms     114.200us       8.347ms        79.62%       8.347ms     417.350us            20  \n",
            "cudnn_infer_volta_scudnn_winograd_128x128_ldg1_ldg4_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.677ms        54.15%       5.677ms     436.692us            13  \n",
            "                           aten::_batch_norm_impl_index         1.21%     141.000us        18.86%       2.206ms     110.300us       0.000us         0.00%       1.221ms      61.050us            20  \n",
            "                                 aten::cudnn_batch_norm         9.12%       1.067ms        17.66%       2.065ms     103.250us       1.221ms        11.65%       1.221ms      61.050us            20  \n",
            "                                       aten::batch_norm         2.09%     245.000us        19.31%       2.258ms     112.900us       0.000us         0.00%       1.104ms      55.200us            20  \n",
            "cudnn_infer_volta_scudnn_128x64_relu_xregs_large_nn_...         0.00%       0.000us         0.00%       0.000us       0.000us     646.000us         6.16%     646.000us     323.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 11.695ms\n",
            "Self CUDA time total: 10.484ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profiling memory consumption\n",
        "\n",
        "`self` - corresponds to the memory allocated (released) by the operator excluding all the children calls to the other operators"
      ],
      "metadata": {
        "id": "bF5SWaaRgaPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18()\n",
        "inputs = torch.randn(5, 3, 224, 224)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU],\n",
        "        profile_memory=True, record_shapes=True) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzsf9ipweLdJ",
        "outputId": "b4caaad6-4510-467f-9b24-4579558c62a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.17%     692.000us         0.17%     692.000us       3.460us      89.10 Mb      89.10 Mb           200  \n",
            "    aten::max_pool2d_with_indices        20.93%      87.142ms        20.93%      87.142ms      87.142ms      11.48 Mb      11.48 Mb             1  \n",
            "                 aten::empty_like         0.03%     112.000us         0.05%     206.000us      10.300us      47.37 Mb       5.74 Mb            20  \n",
            "                      aten::addmm         0.13%     540.000us         0.14%     567.000us     567.000us      19.53 Kb      19.53 Kb             1  \n",
            "                       aten::mean         0.02%      71.000us         0.06%     231.000us     231.000us      10.00 Kb      10.00 Kb             1  \n",
            "              aten::empty_strided         0.00%       6.000us         0.00%       6.000us       6.000us           4 b           4 b             1  \n",
            "                     aten::conv2d         0.05%     192.000us        64.59%     268.842ms      13.442ms      47.37 Mb           0 b            20  \n",
            "                aten::convolution         0.14%     579.000us        64.54%     268.650ms      13.432ms      47.37 Mb           0 b            20  \n",
            "               aten::_convolution         0.09%     369.000us        64.40%     268.071ms      13.404ms      47.37 Mb           0 b            20  \n",
            "         aten::mkldnn_convolution        64.19%     267.191ms        64.31%     267.702ms      13.385ms      47.37 Mb           0 b            20  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 416.256ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "In the below table, aten::conv2d & aten::convolution etc\n",
        "- Are displaying memory usage (CPU Mem)\n",
        "\n",
        "Whereas they have no `Self CPU Mem`. It seems that these are the result of child calls to the operator\n",
        "which is captured in the CPU Mem\n",
        "\"\"\"\n",
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZcZ1fxkgn3a",
        "outputId": "b45c6ad4-e1b0-4b5d-a8e9-0b385b12f653"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.17%     692.000us         0.17%     692.000us       3.460us      89.10 Mb      89.10 Mb           200  \n",
            "                 aten::batch_norm         0.03%     105.000us        12.85%      53.487ms       2.674ms      47.41 Mb           0 b            20  \n",
            "     aten::_batch_norm_impl_index         0.06%     262.000us        12.82%      53.382ms       2.669ms      47.41 Mb           0 b            20  \n",
            "          aten::native_batch_norm        12.65%      52.645ms        12.75%      53.086ms       2.654ms      47.41 Mb     -65.75 Kb            20  \n",
            "                     aten::conv2d         0.05%     192.000us        64.59%     268.842ms      13.442ms      47.37 Mb           0 b            20  \n",
            "                aten::convolution         0.14%     579.000us        64.54%     268.650ms      13.432ms      47.37 Mb           0 b            20  \n",
            "               aten::_convolution         0.09%     369.000us        64.40%     268.071ms      13.404ms      47.37 Mb           0 b            20  \n",
            "         aten::mkldnn_convolution        64.19%     267.191ms        64.31%     267.702ms      13.385ms      47.37 Mb           0 b            20  \n",
            "                 aten::empty_like         0.03%     112.000us         0.05%     206.000us      10.300us      47.37 Mb       5.74 Mb            20  \n",
            "                 aten::max_pool2d         0.01%      47.000us        20.95%      87.189ms      87.189ms      11.48 Mb           0 b             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 416.256ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tracing functionality [ can be opened with chrome trace viewer `chrome:://tracing` ]\n",
        "model = models.resnet18().cuda()\n",
        "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "prof.export_chrome_trace(\"trace.json\")"
      ],
      "metadata": {
        "id": "-rcqUAgbhKMW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining stack trace in profiler (for some reason `Source Location` is not present)\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    with_stack=True,\n",
        ") as prof:\n",
        "    model(inputs)\n",
        "\n",
        "# Print aggregated stats\n",
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXQ-tJbjDvB",
        "outputId": "0f090ccf-eb2f-4361-edaa-c04fe57d3be4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                aten::cudnn_convolution        39.77%       4.067ms        44.41%       4.542ms     227.100us       7.859ms        81.67%       7.859ms     392.950us            20  \n",
            "cudnn_infer_volta_scudnn_winograd_128x128_ldg1_ldg4_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.571ms        57.89%       5.571ms     428.538us            13  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 10.227ms\n",
            "Self CUDA time total: 9.623ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using profiler to analyze long running jobs\n",
        "\n",
        "Parameter `skip_first` tells profiler that it should ignore the first 10 steps (default value of `skip_first` is zero);\n",
        "\n",
        "After the first skip_first steps, profiler starts executing profiler cycles;\n",
        "\n",
        "Each cycle consists of three phases:\n",
        "\n",
        "- idling (wait=5 steps), during this phase profiler is not active;\n",
        "\n",
        "- warming up (warmup=1 steps), during this phase profiler starts tracing, but the results are discarded; this phase is used to discard the samples obtained by the profiler at the beginning of the trace since they are usually skewed by an extra overhead;\n",
        "\n",
        "- active tracing (active=3 steps), during this phase profiler traces and records data;\n",
        "\n",
        "An optional repeat parameter specifies an upper bound on the number of cycles. By default (zero value), profiler will execute cycles as long as the job runs.\n",
        "\n",
        "Whenever a trace is available the profiler calls the user defined `trace handler function`. The profiler pass a reference of itself to this function which can be used for creating tables etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "svfPlzV2whk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using profiler to analyze long running jobs\n",
        "from torch.profiler import schedule\n",
        "\n",
        "# generate a schedule\n",
        "my_schedule = schedule(\n",
        "    skip_first=10,\n",
        "    wait=5,\n",
        "    warmup=1,\n",
        "    active=3,\n",
        "    repeat=2)"
      ],
      "metadata": {
        "id": "_v1GG4mHtm3N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trace_handler(p):\n",
        "    output = p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10)\n",
        "    print(output)\n",
        "    p.export_chrome_trace(\"trace_\" + str(p.step_num) + \".json\")\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    schedule=torch.profiler.schedule(\n",
        "        wait=1,\n",
        "        warmup=1,\n",
        "        active=2),\n",
        "    on_trace_ready=trace_handler\n",
        ") as p:\n",
        "    for idx in range(8):\n",
        "        model(inputs)\n",
        "        p.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWQDa0zPv1Nf",
        "outputId": "9bd26478-76e2-4633-ea25-3c61a05f69ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                aten::cudnn_convolution        10.10%       2.991ms        14.75%       4.366ms     109.150us      15.738ms        81.60%      15.738ms     393.450us            40  \n",
            "cudnn_infer_volta_scudnn_winograd_128x128_ldg1_ldg4_...         0.00%       0.000us         0.00%       0.000us       0.000us      11.145ms        57.79%      11.145ms     428.654us            26  \n",
            "                                 aten::cudnn_batch_norm         8.79%       2.603ms        20.10%       5.950ms     148.750us       2.016ms        10.45%       2.016ms      50.400us            40  \n",
            "cudnn_infer_volta_scudnn_128x32_sliced1x4_ldg4_relu_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.326ms         6.88%       1.326ms     221.000us             6  \n",
            "      cudnn_infer_volta_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.161ms         6.02%       1.161ms     290.250us             4  \n",
            "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us       1.075ms         5.57%       1.075ms      35.833us            30  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us       1.073ms         5.56%       1.073ms      41.269us            26  \n",
            "      cudnn_infer_volta_scudnn_128x128_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     660.000us         3.42%     660.000us     165.000us             4  \n",
            "                                       aten::clamp_min_         1.91%     566.000us        16.61%       4.917ms     144.618us     623.000us         3.23%     623.000us      18.324us            34  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     623.000us         3.23%     623.000us      18.324us            34  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 29.609ms\n",
            "Self CUDA time total: 19.287ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                aten::cudnn_convolution        11.34%       2.602ms        18.36%       4.212ms     105.300us      15.724ms        81.20%      15.724ms     393.100us            40  \n",
            "cudnn_infer_volta_scudnn_winograd_128x128_ldg1_ldg4_...         0.00%       0.000us         0.00%       0.000us       0.000us      11.144ms        57.55%      11.144ms     428.615us            26  \n",
            "                                 aten::cudnn_batch_norm         9.91%       2.274ms        22.54%       5.170ms     129.250us       2.014ms        10.40%       2.014ms      50.350us            40  \n",
            "cudnn_infer_volta_scudnn_128x32_sliced1x4_ldg4_relu_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.325ms         6.84%       1.325ms     220.833us             6  \n",
            "      cudnn_infer_volta_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.161ms         6.00%       1.161ms     290.250us             4  \n",
            "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us       1.120ms         5.78%       1.120ms      36.129us            31  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us       1.061ms         5.48%       1.061ms      40.808us            26  \n",
            "      cudnn_infer_volta_scudnn_128x128_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     660.000us         3.41%     660.000us     165.000us             4  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     622.000us         3.21%     622.000us      17.771us            35  \n",
            "                                       aten::clamp_min_         2.35%     540.000us         4.00%     918.000us      27.000us     618.000us         3.19%     618.000us      18.176us            34  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 22.936ms\n",
            "Self CUDA time total: 19.365ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOEjxCGUwO_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}